{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5b879b-5b69-47f4-9993-46ab31e7fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from smogn import smoter\n",
    "os.chdir('C:\\\\Users\\\\Owner\\\\Documents\\\\School\\\\University Year 4\\\\Semester 2\\\\Honours Project\\\\distributed-resampling-parallelization')  # Move up to the parent directory\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from src.relevance.phi import Phi\n",
    "from src.sampling.mixed_sampling.distributed_smogn import DistributedSMOGN\n",
    "from src.sampling.over_sampling.distributed_ros import DistributedROS\n",
    "from src.sampling.under_sampling.distributed_rus import DistributedRUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c682212e-4ca2-4414-b60f-adac800c972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "DATA_RAW_DIR = f\"{DATA_DIR}/raw\"\n",
    "DATA_PROCESSED_DIR = f\"{DATA_DIR}/processed\"\n",
    "\n",
    "RESULT_DIR = \"results\"\n",
    "RESULT_EXECUTION_TIME_DIR = f\"{RESULT_DIR}\"\n",
    "RESULT_PREDICTIVE_PERFORMANCE_DIR = \"{RESULT_DIR}/predictive_performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181a0fef-e87b-4584-8cd5-62b287c4d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    # \"boston\": \"HousValue\",\n",
    "    # \"Abalone\": \"Rings\",\n",
    "    # \"bank8FM\": \"rej\",\n",
    "    # \"heat\": \"heat\",\n",
    "    # \"cpuSm\": \"usr\",\n",
    "    # \"energy\": \"Appliances\",\n",
    "    # \"superconductivity\": \"critical_temp\",\n",
    "    \"sales\": \"Sale Amount\"\n",
    "}\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    \"ros\": {\n",
    "        \"name\": \"ROS\",\n",
    "        \"type\": \"dist\",\n",
    "        \"sampler\": DistributedROS\n",
    "    },\n",
    "    \"rus\": {\n",
    "        \"name\": \"RUS\",\n",
    "        \"type\": \"dist\",\n",
    "        \"sampler\": DistributedRUS\n",
    "    },\n",
    "    \"smogn\": {\n",
    "        \"name\": \"SMOGN\",\n",
    "        \"type\": \"seq\",\n",
    "        \"sampler\": smoter\n",
    "    },\n",
    "    \"dist_smogn\": {\n",
    "        \"name\": \"Distributed SMOGN\",\n",
    "        \"type\": \"dist\",\n",
    "        \"sampler\": DistributedSMOGN,\n",
    "        \"k_partitions\": [2, 4, 8]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18ad90c-487b-4848-af03-8ff4780b4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[4]').appName('Distributed Resampling').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65b79e0-d76d-4a2e-9b96-da039535548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b1bbcf-04d8-4db0-849a-5dae1c65cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_23244\\1929852937.py:5: DtypeWarning: Columns (8,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{DATA_RAW_DIR}/{dataset}.csv\")\n"
     ]
    }
   ],
   "source": [
    "for dataset, label_col in DATASETS.items():\n",
    "    DATA_PROCESSED_TRAIN_DIR = f\"{DATA_PROCESSED_DIR}/{dataset}/train\"\n",
    "    DATA_PROCESSED_TEST_DIR = f\"{DATA_PROCESSED_DIR}/{dataset}/test\"\n",
    "\n",
    "    df = pd.read_csv(f\"{DATA_RAW_DIR}/{dataset}.csv\")\n",
    "\n",
    "    df = spark.createDataFrame(df)\n",
    "\n",
    "    relevance_col = \"phi\"\n",
    "    df = Phi(input_col=label_col, output_col=relevance_col).transform(df)\n",
    "\n",
    "    train, test = df.randomSplit(weights=[0.8, 0.2])\n",
    "    train = train.sample(fraction=0.01)\n",
    "    train = train.drop(relevance_col)\n",
    "    test = test.toPandas()\n",
    "    phi = test.pop(relevance_col)\n",
    "\n",
    "    test.to_csv(f\"{DATA_PROCESSED_TEST_DIR}/{dataset}.csv\", index=False)\n",
    "    phi.to_csv(f\"{DATA_PROCESSED_TEST_DIR}/{dataset}_phi.csv\", index=False)\n",
    "\n",
    "    execution_times[dataset] = {}\n",
    "\n",
    "    train_base = train.toPandas()\n",
    "    train_base.to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_rus = DistributedRUS(label_col=label_col, k_partitions=1).transform(train)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"RUS\"] = round(end_time - start_time, 3)\n",
    "    # train_rus.toPandas().to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_rus.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_ros = DistributedROS(label_col=label_col, k_partitions=1).transform(train)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"ROS\"] = round(end_time - start_time, 3)\n",
    "    # train_ros.toPandas().to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_ros.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_smogn = smoter(data=train.toPandas(), y=label_col)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"SMOGN\"] = round(end_time - start_time, 3)\n",
    "    # train_smogn.to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_smogn.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_dist_smogn_2 = DistributedSMOGN(label_col=label_col, k_partitions=2).transform(train)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"Distributed SMOGN (k_partitions = 2)\"] = round(end_time - start_time, 3)\n",
    "    # train_dist_smogn_2.toPandas().to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_dist_smogn_2.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_dist_smogn_4 = DistributedSMOGN(label_col=label_col, k_partitions=4).transform(train)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"Distributed SMOGN (k_partitions = 4)\"] = round(end_time - start_time, 3)\n",
    "    # train_dist_smogn_4.toPandas().to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_dist_smogn_4.csv\", index=False)\n",
    "\n",
    "    # start_time = time.time()\n",
    "    # train_dist_smogn_8 = DistributedSMOGN(label_col=label_col, k_partitions=8).transform(train)\n",
    "    # end_time = time.time()\n",
    "    # execution_times[dataset][\"Distributed SMOGN (k_partitions = 8)\"] = round(end_time - start_time, 3)\n",
    "    # train_dist_smogn_8.toPandas().to_csv(f\"{DATA_PROCESSED_TRAIN_DIR}/{dataset}_dist_smogn_8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2affa5-93d4-48b7-80cb-d7ffa9c91aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=execution_times).to_csv(f\"{RESULT_EXECUTION_TIME_DIR}/execution_time.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
